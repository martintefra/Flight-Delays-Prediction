{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/9l9kqd013xjdlz8_0b2__8xr0000gq/T/ipykernel_98598/617258117.py:1: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/flights.csv').sample(frac=0.1).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/flights.csv').sample(frac=0.1).reset_index(drop=True)\n",
    "df_airports = pd.read_csv('data/airports.csv')\n",
    "df_airlines = pd.read_csv('data/airlines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# some cleaning\n",
    "df = df[['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'AIRLINE', 'DISTANCE']]\n",
    "\n",
    "df = df.dropna()\n",
    "# discard flights with airport codes that are not in the airports dataset\n",
    "df = df[df['ORIGIN_AIRPORT'].isin(df_airports['IATA_CODE'])]\n",
    "# discard flights with airline codes that are not in the airlines dataset\n",
    "df = df[df['AIRLINE'].isin(df_airlines['IATA_CODE'])]\n",
    "df = df.sample(frac=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORIGIN_AIRPORT'] = pd.Categorical(df['ORIGIN_AIRPORT'])\n",
    "df['DESTINATION_AIRPORT'] = pd.Categorical(df['DESTINATION_AIRPORT'])\n",
    "df['AIRLINE'] = pd.Categorical(df['AIRLINE'])\n",
    "\n",
    "df['ORIGIN_AIRPORT'] = df['ORIGIN_AIRPORT'].cat.codes\n",
    "df['DESTINATION_AIRPORT'] = df['DESTINATION_AIRPORT'].cat.codes\n",
    "df['AIRLINE'] = df['AIRLINE'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220351</th>\n",
       "      <td>149</td>\n",
       "      <td>189</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68305</th>\n",
       "      <td>236</td>\n",
       "      <td>140</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471781</th>\n",
       "      <td>246</td>\n",
       "      <td>312</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193398</th>\n",
       "      <td>141</td>\n",
       "      <td>37</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288491</th>\n",
       "      <td>181</td>\n",
       "      <td>273</td>\n",
       "      <td>140.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292947</th>\n",
       "      <td>207</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257319</th>\n",
       "      <td>279</td>\n",
       "      <td>165</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186137</th>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548834</th>\n",
       "      <td>225</td>\n",
       "      <td>200</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304111</th>\n",
       "      <td>84</td>\n",
       "      <td>223</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52293 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ORIGIN_AIRPORT  DESTINATION_AIRPORT  DEPARTURE_DELAY  ARRIVAL_DELAY  \\\n",
       "220351             149                  189             -6.0          -17.0   \n",
       "68305              236                  140             -3.0          -35.0   \n",
       "471781             246                  312             17.0           11.0   \n",
       "193398             141                   37             -5.0           -7.0   \n",
       "288491             181                  273            140.0          154.0   \n",
       "...                ...                  ...              ...            ...   \n",
       "292947             207                   20              0.0           -5.0   \n",
       "257319             279                  165             -9.0          -11.0   \n",
       "186137             233                  234             -6.0            4.0   \n",
       "548834             225                  200             25.0            8.0   \n",
       "304111              84                  223             -6.0          -26.0   \n",
       "\n",
       "        AIRLINE  DISTANCE  \n",
       "220351        8       854  \n",
       "68305         0      2917  \n",
       "471781        1        31  \n",
       "193398       13       670  \n",
       "288491        2       354  \n",
       "...         ...       ...  \n",
       "292947        4       302  \n",
       "257319        1        95  \n",
       "186137       11      1009  \n",
       "548834        9        67  \n",
       "304111        0       888  \n",
       "\n",
       "[52293 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DEPARTURE_DELAY', 'AIRLINE', 'DISTANCE']]\n",
    "y = df['ARRIVAL_DELAY']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class FlightDelayModel(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim):\n",
    "        super(FlightDelayModel, self).__init__()\n",
    "        self.conv1 = GCNConv(node_feature_dim, 128)\n",
    "        self.conv2 = GCNConv(128, 32)\n",
    "        self.edge_pred = torch.nn.Linear(edge_feature_dim, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_features):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.edge_pred(torch.cat([x[edge_index[0]], x[edge_index[1]], edge_features], dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FlightDelayModel.forward() missing 2 required positional arguments: 'edge_index' and 'edge_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m numerical_data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumerical_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Informatik/Swisscom/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Informatik/Swisscom/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: FlightDelayModel.forward() missing 2 required positional arguments: 'edge_index' and 'edge_features'"
     ]
    }
   ],
   "source": [
    "model = FlightDelayModel(X_train_tensor.shape[1], 1)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss for regression tasks\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:  # Assume you have a DataLoader `train_loader`\n",
    "        optimizer.zero_grad()   \n",
    "        numerical_data = batch[0]\n",
    "        targets = batch[1]\n",
    "        outputs = model(numerical_data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10459,) (10459,)\n",
      "Mean Absolute Error: 21.97\n",
      "Mean Squared Error: 1818.16\n",
      "Root Mean Squared Error: 42.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions, actuals = [], []\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for batch in test_loader:  # Assume you have a DataLoader `test_loader`\n",
    "        numerical_data = batch[0]\n",
    "        targets = batch[1]\n",
    "        outputs = model(numerical_data).squeeze()\n",
    "        \n",
    "        # Store predictions and actual values\n",
    "        predictions.extend(outputs.tolist())\n",
    "        actuals.extend(targets.tolist())\n",
    "\n",
    "# Convert lists to NumPy arrays for evaluation\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print(actuals.shape, predictions.shape)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "print(f'Mean Absolute Error: {mae:.2f}')\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teframartin/Informatik/Swisscom/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 3327\n",
      "  NumEdges: 9228\n",
      "  NumFeats: 3703\n",
      "  NumClasses: 6\n",
      "  NumTrainingSamples: 120\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "\n",
    "dataset = dgl.data.CiteseerGraphDataset()\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=3327, num_edges=9228,\n",
       "      ndata_schemes={'feat': Scheme(shape=(3703,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "n_users = 1000\n",
    "n_items = 500\n",
    "n_follows = 3000\n",
    "n_clicks = 5000\n",
    "n_dislikes = 500\n",
    "n_hetero_features = 10\n",
    "n_user_classes = 5\n",
    "n_max_clicks = 10\n",
    "\n",
    "follow_src = np.random.randint(0, n_users, n_follows)\n",
    "follow_dst = np.random.randint(0, n_users, n_follows)\n",
    "click_src = np.random.randint(0, n_users, n_clicks)\n",
    "click_dst = np.random.randint(0, n_items, n_clicks)\n",
    "dislike_src = np.random.randint(0, n_users, n_dislikes)\n",
    "dislike_dst = np.random.randint(0, n_items, n_dislikes)\n",
    "\n",
    "hetero_graph = dgl.heterograph({\n",
    "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
    "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
    "    ('user', 'click', 'item'): (click_src, click_dst),\n",
    "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
    "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
    "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})\n",
    "\n",
    "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users, n_hetero_features)\n",
    "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items, n_hetero_features)\n",
    "hetero_graph.nodes['user'].data['label'] = torch.randint(0, n_user_classes, (n_users,))\n",
    "hetero_graph.edges['click'].data['label'] = torch.randint(1, n_max_clicks, (n_clicks,)).float()\n",
    "# randomly generate training masks on user nodes and click edges\n",
    "hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6)\n",
    "hetero_graph.edges['click'].data['train_mask'] = torch.zeros(n_clicks, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = graph.ndata['feat']\n",
    "node_labels = graph.ndata['label']\n",
    "train_mask = graph.ndata['train_mask']\n",
    "valid_mask = graph.ndata['val_mask']\n",
    "test_mask = graph.ndata['test_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3327, 3703]), torch.Size([3327]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata[\"feat\"].shape, graph.ndata[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3703, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features, n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7923964262008667\n",
      "1.7791969776153564\n",
      "1.7661806344985962\n",
      "1.7529937028884888\n",
      "1.7394185066223145\n",
      "1.7253941297531128\n",
      "1.7108708620071411\n",
      "1.695776104927063\n",
      "1.6801279783248901\n",
      "1.6639060974121094\n"
     ]
    }
   ],
   "source": [
    "model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    # forward propagation by using all nodes\n",
    "    logits = model(graph, node_features)\n",
    "    # compute loss\n",
    "    loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
    "    # compute validation accuracy\n",
    "    acc = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
    "    # backward propagation\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())\n",
    "\n",
    "    # Save model if necessary.  Omitted in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
